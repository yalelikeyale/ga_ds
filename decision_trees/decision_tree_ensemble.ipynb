{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "### Training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import KFold\n",
    "from mlens.visualization import corrmat\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display                               \n",
    "from ipywidgets import interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(ytest, P_base_learners, P_ensemble, labels, ens_label):\n",
    "    \"\"\"Plot the roc curve for base learners and ensemble.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    \n",
    "    cm = [plt.cm.rainbow(i)\n",
    "      for i in np.linspace(0, 1.0, P_base_learners.shape[1] + 1)]\n",
    "    \n",
    "    for i in range(P_base_learners.shape[1]):\n",
    "        p = P_base_learners[:, i]\n",
    "        fpr, tpr, _ = roc_curve(ytest, p)\n",
    "        plt.plot(fpr, tpr, label=labels[i], c=cm[i + 1])\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(ytest, P_ensemble)\n",
    "    plt.plot(fpr, tpr, label=ens_label, c=cm[0])\n",
    "        \n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 222\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/election.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Split Data into train and test sets.\"\"\"\n",
    "y = 1 * (df.cand_pty_affiliation == \"REP\")\n",
    "X = df.drop([\"cand_pty_affiliation\"], axis=1)\n",
    "\n",
    "X = pd.get_dummies(X, sparse=True)\n",
    "X.drop(X.columns[X.std() == 0], axis=1, inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.95, random_state=seed)\n",
    "labels = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163b51f34dbd4e719b08340ed446c800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='crit', options=('gini', 'entropy'), value='gini'), Dropdown(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_roc_auc(fpr, tpr, roc_auc):\n",
    "    # method I: plt\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "def plot_tree(crit, split, depth, min_split, min_leaf=0.2, min_decrease=0.001):\n",
    "    estimator = DecisionTreeClassifier(random_state = 0\n",
    "        , criterion=crit\n",
    "        , splitter = split\n",
    "        , max_depth = depth\n",
    "        , min_samples_split=min_split\n",
    "        , min_samples_leaf=min_leaf\n",
    "        , min_impurity_decrease = min_decrease)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    graph = Source(tree.export_graphviz(estimator\n",
    "          , out_file=None\n",
    "          , feature_names=labels\n",
    "          , class_names=['Dem','Rep']\n",
    "          , filled = True))\n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    probs = estimator.predict_proba(X_test)[:,1]\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    fpr, tpr, threshold = roc_curve(y_test, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    display(roc_auc_score(y_test, y_pred))\n",
    "    display_roc_auc(fpr, tpr, roc_auc)\n",
    "    display(SVG(graph.pipe(format='svg')))\n",
    "    return estimator\n",
    "\n",
    "inter=interactive(plot_tree\n",
    "   , crit = [\"gini\", \"entropy\"]\n",
    "   , split = [\"best\"]\n",
    "   , depth=np.linspace(1, 35, 35, endpoint=True)\n",
    "   , min_split=np.linspace(.01, .5, 100)\n",
    "   , min_leaf=np.linspace(.01, .5, 100)\n",
    "   , min_decrease=np.linspace(.001, .01, 100)\n",
    ")\n",
    "display(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = DecisionTreeClassifier(max_depth=10, min_samples_leaf=0.01, min_samples_split=0.01, min_impurity_decrease=0.004, random_state=0)\n",
    "dt1.fit(X_train, y_train)\n",
    "dt1_proba = dt1.predict_proba(X_test)\n",
    "y_pred = dt1.predict(X_test)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Split Data into train and test sets.\"\"\"\n",
    "y = 1 * (df.cand_pty_affiliation == \"REP\")\n",
    "X = df.drop([\"cand_pty_affiliation\",\"transaction_amt\"], axis=1)\n",
    "\n",
    "X = pd.get_dummies(X, sparse=True)\n",
    "X.drop(X.columns[X.std() == 0], axis=1, inplace=True)\n",
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "labels = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_roc_auc(fpr, tpr, roc_auc):\n",
    "    # method I: plt\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "def plot_tree(crit, split, depth, min_split, min_leaf=0.2, min_decrease=0.001):\n",
    "    estimator = DecisionTreeClassifier(random_state = 0\n",
    "        , criterion=crit\n",
    "        , splitter = split\n",
    "        , max_depth = depth\n",
    "        , min_samples_split=min_split\n",
    "        , min_samples_leaf=min_leaf\n",
    "        , min_impurity_decrease = min_decrease)\n",
    "    estimator.fit(X_train_red, y_train_red)\n",
    "    graph = Source(tree.export_graphviz(estimator\n",
    "          , out_file=None\n",
    "          , feature_names=labels\n",
    "          , class_names=['Dem','Rep']\n",
    "          , filled = True))\n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    probs = estimator.predict_proba(X_test_red)[:,1]\n",
    "    y_pred = estimator.predict(X_test_red)\n",
    "    display(roc_auc_score(y_test_red, y_pred))\n",
    "    fpr, tpr, threshold = roc_curve(y_test_red, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    display_roc_auc(fpr, tpr, roc_auc)\n",
    "    display(SVG(graph.pipe(format='svg')))\n",
    "    return estimator\n",
    "\n",
    "inter=interactive(plot_tree\n",
    "   , crit = [\"gini\", \"entropy\"]\n",
    "   , split = [\"best\"]\n",
    "   , depth=np.linspace(1, 35, 35, endpoint=True)\n",
    "   , min_split=np.linspace(.01, .5, 100)\n",
    "   , min_leaf=np.linspace(.01, .5, 100)\n",
    "   , min_decrease=np.linspace(.001, .01, 100)\n",
    ")\n",
    "display(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt2 = DecisionTreeClassifier(max_depth=5, min_samples_leaf=0.01, min_samples_split=0.01, min_impurity_decrease=0.003, random_state=0)\n",
    "dt2.fit(X_train_red, y_train_red)\n",
    "dt2_proba = dt2.predict_proba(X_test_red)\n",
    "y_pred = dt2.predict(X_test_red)\n",
    "roc_auc_score(y_test_red, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = dt1_proba[:,1]\n",
    "p2 = dt2_proba[:,1]\n",
    "\n",
    "display(sns.heatmap(pd.DataFrame({\"full_data\": p1,\n",
    "              \"red_data\": p2}).corr(), annot=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.mean([p1,p2], axis=0)\n",
    "roc_auc_score(y_test, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Ensemble w/ DT vs Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    max_features=3,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "p = rf.predict_proba(X_test)[:, 1]\n",
    "print(\"Average of decision tree ROC-AUC score: %.3f\" % roc_auc_score(y_test, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using array of model types as base learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    \"\"\"Generate a library of base learners.\"\"\"\n",
    "    nb = GaussianNB()\n",
    "    svc = SVC(C=30, kernel='rbf', probability=True, verbose=3)\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    lr = LogisticRegression(C=30, random_state=seed)\n",
    "    nn = MLPClassifier((80, 10), early_stopping=False, random_state=seed)\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, random_state=seed)\n",
    "    rf = RandomForestClassifier(n_estimators=10, max_features=3, random_state=seed)\n",
    "\n",
    "    models = {'svm': svc,\n",
    "              'knn': knn,\n",
    "              'naive bayes': nb,\n",
    "              'mlp-nn': nn,\n",
    "              'random forest': rf,\n",
    "              'gbm': gb,\n",
    "              'logistic': lr,\n",
    "              }\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(model_list):\n",
    "    \"\"\"Fit models in list on training set and return preds\"\"\"\n",
    "    P = np.zeros((y_test.shape[0], len(model_list)))\n",
    "    P = pd.DataFrame(P)\n",
    "\n",
    "    print(\"Fitting models.\")\n",
    "    cols = list()\n",
    "    for i, (name, m) in enumerate(models.items()):\n",
    "        print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        m.fit(X_train, y_train)\n",
    "        P.iloc[:, i] = m.predict_proba(X_test)[:, 1]\n",
    "        cols.append(name)\n",
    "        print(\"done\")\n",
    "\n",
    "    P.columns = cols\n",
    "    print(\"Done.\\n\")\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_models(P, y):\n",
    "    \"\"\"Score model in prediction DF\"\"\"\n",
    "    print(\"Scoring models.\")\n",
    "    for m in P.columns:\n",
    "        score = roc_auc_score(y, P.loc[:, m])\n",
    "        print(\"%-26s: %.3f\" % (m, score))\n",
    "    print(\"Done.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()\n",
    "P = train_predict(models)\n",
    "score_models(P, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat(P.corr(), inflate=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat(P.apply(lambda pred: 1*(pred >= 0.5) - y_test.values).corr(), inflate=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ensemble ROC-AUC score: %.3f\" % roc_auc_score(y_test, P.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = P.apply(lambda x: 1*(x >= 0.5).value_counts(normalize=True))\n",
    "p.index = [\"DEM\", \"REP\"]\n",
    "p.loc[\"REP\", :].sort_values().plot(kind=\"bar\")\n",
    "plt.axhline(0.25, color=\"k\", linewidth=0.5)\n",
    "plt.text(0., 0.23, \"True share republicans\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include = [c for c in P.columns if c not in [\"mlp-nn\"]]\n",
    "print(\"Truncated ensemble ROC-AUC score: %.3f\" % roc_auc_score(y_test, P.loc[:, include].mean(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a meta learner and randomizing training data using K fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learners = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner = GradientBoostingClassifier(\n",
    "    n_estimators=1000,\n",
    "    loss=\"exponential\",\n",
    "    max_features=4,\n",
    "    max_depth=3,\n",
    "    subsample=0.5,\n",
    "    learning_rate=0.005, \n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_base, xpred_base, ytrain_base, ypred_base = train_test_split(X_train, y_train, test_size=0.5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_learners(base_learners, inp, out, verbose=True):\n",
    "    \"\"\"Train all base learners in the library.\"\"\"\n",
    "    if verbose: print(\"Fitting models.\")\n",
    "    for i, (name, m) in enumerate(base_learners.items()):\n",
    "        if verbose: print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        m.fit(inp, out)\n",
    "        if verbose: print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_learners(base_learners, xtrain_base, ytrain_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_base_learners(pred_base_learners, inp, verbose=True):\n",
    "    \"\"\"Generate a prediction matrix.\"\"\"\n",
    "    P = np.zeros((inp.shape[0], len(pred_base_learners)))\n",
    "\n",
    "    if verbose: print(\"Generating base learner predictions.\")\n",
    "    for i, (name, m) in enumerate(pred_base_learners.items()):\n",
    "        if verbose: print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        p = m.predict_proba(inp)\n",
    "        # With two classes, need only predictions for one class\n",
    "        P[:, i] = p[:, 1]\n",
    "        if verbose: print(\"done\")\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_base = predict_base_learners(base_learners, xpred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner.fit(P_base, ypred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(base_learners, meta_learner, inp, verbose=True):\n",
    "    \"\"\"Generate predictions from the ensemble.\"\"\"\n",
    "    P_pred = predict_base_learners(base_learners, inp, verbose=verbose)\n",
    "    return P_pred, meta_learner.predict_proba(P_pred)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_pred, p = ensemble_predict(base_learners, meta_learner, X_test)\n",
    "print(\"\\nEnsemble ROC-AUC score: %.3f\" % roc_auc_score(y_test, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking(base_learners, meta_learner, X, y, generator):\n",
    "    \"\"\"Simple training routine for stacking.\"\"\"\n",
    "\n",
    "    # Train final base learners for test time\n",
    "    print(\"Fitting final base learners...\", end=\"\")\n",
    "    train_base_learners(base_learners, X, y, verbose=False)\n",
    "    print(\"done\")\n",
    "\n",
    "    # Generate predictions for training meta learners\n",
    "    # Outer loop:\n",
    "    print(\"Generating cross-validated predictions...\")\n",
    "    cv_preds, cv_y = [], []\n",
    "    for i, (train_idx, test_idx) in enumerate(generator.split(X)):\n",
    "\n",
    "        fold_xtrain, fold_ytrain = X[train_idx, :], y[train_idx]\n",
    "        fold_xtest, fold_ytest = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        # Inner loop: step 4 and 5\n",
    "        fold_base_learners = {name: clone(model)\n",
    "                              for name, model in base_learners.items()}\n",
    "        train_base_learners(\n",
    "            fold_base_learners, fold_xtrain, fold_ytrain, verbose=False)\n",
    "\n",
    "        fold_P_base = predict_base_learners(\n",
    "            fold_base_learners, fold_xtest, verbose=False)\n",
    "\n",
    "        cv_preds.append(fold_P_base)\n",
    "        cv_y.append(fold_ytest)\n",
    "        print(\"Fold %i done\" % (i + 1))\n",
    "\n",
    "    print(\"CV-predictions done\")\n",
    "    \n",
    "    # Be careful to get rows in the right order\n",
    "    cv_preds = np.vstack(cv_preds)\n",
    "    cv_y = np.hstack(cv_y)\n",
    "\n",
    "    # Train meta learner\n",
    "    print(\"Fitting meta learner...\", end=\"\")\n",
    "    meta_learner.fit(cv_preds, cv_y)\n",
    "    print(\"done\")\n",
    "\n",
    "    return base_learners, meta_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with stacking\n",
    "cv_base_learners, cv_meta_learner = stacking(\n",
    "    get_models(), clone(meta_learner), X_train.values, y_train.values, KFold(2))\n",
    "\n",
    "P_pred, p = ensemble_predict(cv_base_learners, cv_meta_learner, X_test, verbose=False)\n",
    "print(\"\\nEnsemble ROC-AUC score: %.3f\" % roc_auc_score(y_test, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "\n",
    "# Instantiate the ensemble with 10 folds\n",
    "sl = SuperLearner(\n",
    "    folds=10,\n",
    "    random_state=seed,\n",
    "    verbose=2,\n",
    "    backend=\"multiprocessing\"\n",
    ")\n",
    "\n",
    "# Add the base learners and the meta learner\n",
    "sl.add(list(base_learners.values()), proba=True) \n",
    "sl.add_meta(meta_learner, proba=True)\n",
    "\n",
    "# Train the ensemble\n",
    "sl.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "p_sl = sl.predict_proba(X_test)\n",
    "\n",
    "print(\"\\nSuper Learner ROC-AUC score: %.3f\" % roc_auc_score(y_test, p_sl[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_test, p.reshape(-1, 1), P.mean(axis=1), [\"Simple average\"], \"Super Learner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
